---
title: "Konsistente Charaktere und Künstliche Intelligenz"
author: "Jörg Kantel"
date: "2024-02-09 20:45:00"
categories: [Künstliche Intelligenz, Bilder, Stable Diffusion, DreamStudio, Scenario, Spieleprogrammierung, Interactive Fiction, Tuesday JS]
image: "images/entrancehallmockup.jpg"
---

[![](images/entrancehallmockup-b.jpg)](https://www.flickr.com/photos/schockwellenreiter/53518059577/)

Es ist ziemlich schwierig, mit den derzeitigen Werkzeugen der gekünstelten Intelligenzia wenigstens einigermaßen konsistente Charaktere zu generieren. Zwar gibt es auf YouTube eine große Anzahl von Videos, die behaupten, Lösungen für das Problem gefunden zu haben, jedoch ist das, was sie unter »Charakterkonsistenz« verstehen, meist weit von dem entfernt, was man zum Beispiel bei Avataren für eine *Visual Novel* benötigt.

Bei interaktiven Geschichten, die man etwa mit [Twine](http://cognitiones.kantel-chaos-team.de/multimedia/spieleprogrammierung/twine2.html) erstellt, kann man das Problem meistens großzügig ignorieren und einfach hoffen, daß der Leserin/Spielerin oder dem Leser/Spieler die Brüche in den Zeichnungen nicht störend auffallen, da meist in der Regel die Abbildung je auf einer separaten Seite für sich alleine steht (vergleiche die [Smashing Pumpkins](https://kantel.github.io/posts/2023111901_smashing_pumpkins_devlog_3/), wo ich wild Bilder zusammengemixt hatte). Aber zum Beispiel bei *Visual Novels* in [Ren'Py](http://cognitiones.kantel-chaos-team.de/multimedia/spieleprogrammierung/renpy.html) oder [Tuesday&nbsp;JS](http://cognitiones.kantel-chaos-team.de/multimedia/spieleprogrammierung/tuesdayjs.html) sieht die Sache schon anders aus.

Und da ich momentan an [ersten Tests mit Tuesday&nbsp;JS](https://kantel.github.io/posts/2024020801_tuesdayjs_update/) arbeite, wurde ich mit dem Problem konfrontiert, und ich glaube, eine Lösung gefunden zu haben, die mich erst einmal zufriedenstellt. Für diesen Prototypen habe ich zwei Charaktere (einen Privatdetektiv und ein Zimmermädchen) mit [Scenario](https://app.scenario.com/) generiert (ich habe jeweils bestimmt je 100 Versuche gestartet, bis ich endlich mit den Ergebnissen zufrieden war).

[![Zimmermädchen](images/maid_orig.jpg)](https://www.flickr.com/photos/schockwellenreiter/53515278291/){.lightbox}&nbsp;[![Privatdetektiv](images/priveye_orig.jpg)](https://www.flickr.com/photos/schockwellenreiter/53517612235/){.lightbox}

Diese Bilder habe ich dann in [DreamStudio](https://beta.dreamstudio.ai/generate) importiert und als Grundlage für ein *»Image to Image« Refinement* genommen (das geht auch in Scenario, aber ich bin momentan einfach mit DreamStudio vertrauter -- die vielen LoRAS in Scenario verwirren mich einfach, da greife ich doch lieber auf das gewohnte *Comic Book* zurück). Dort habe ich dann mit dem gleichen Prompt Variationen generiert, in dem ich an zweiter Position den Prompt um die gewünschten *facial expressions* ergänzt hatte (zum Beispiel *angry*, *confused*, *sad*, *smiling* oder *talking*). Und weil ich den Detektiv eigentlich ohne Brille haben wollte, habe ich seinem Negativ-Prompt noch ein *looking glass* spendiert. Nicht alle Bilder waren produktionsreif, aber die besten sahen so aus -- bei dem Zimmermädchen (Auswahl):

[![Zimmermädchen sehr traurig](images/maid01.jpg)](https://www.flickr.com/photos/schockwellenreiter/53519145519/){.lightbox}&nbsp;[![Zimmermädchen sprechend](images/maid02.jpg)](https://www.flickr.com/photos/schockwellenreiter/53519142594/){.lightbox}&nbsp;[![Zimmermädchen fröhlich](images/maid03.jpg)](https://www.flickr.com/photos/schockwellenreiter/53518827531/){.lightbox}<br /><br />
[![Zimmermädchen verwirrt](images/maid04.jpg)](https://www.flickr.com/photos/schockwellenreiter/53519248330/){.lightbox}&nbsp;[![Zimmermädchen verärgert](images/maid05.jpg)]{.lightbox}

Oder bei dem Detektiv (ebenfalls nur eine Auswahl):

[![Privatdetektiv sehr traurig](images/priveye01.jpg)](https://www.flickr.com/photos/schockwellenreiter/53519169229/){.lightbox}&nbsp;[![Privatdetektiv sprechend](images/priveye02.jpg)](https://www.flickr.com/photos/schockwellenreiter/53519168809/){.lightbox}&nbsp;[![Privatdetektiv fröhlich](images/priveye03.jpg)](https://www.flickr.com/photos/schockwellenreiter/53517964722/){.lightbox}<br /><br />
[![Privatdetektiv verwirrt](images/priveye04.jpg)](https://www.flickr.com/photos/schockwellenreiter/53519012558/){.lightbox}&nbsp;[![Privatdetektiv verärgert](images/priveye05.jpg)](https://www.flickr.com/photos/schockwellenreiter/53519156939/){.lightbox}

Diese Bilder habe ich dann mit dem [kürzlich entdecken Rembg](https://kantel.github.io/posts/2024020702_rembg/) vom Hintergrund freigestellt und kann sie nun als Avatare in (m)einer *Visual Novel* nutzen. Als *Proof of Concept* habe ich zwei von ihnen in das *Mockup* des Bannerbilds oben einkopiert.

Ich will ehrlich sein: Erstens ist es mit Sicherheit nicht das, was versierte Pixelartisten daraus hätten machen können (aber hey, es ist nur eine Maschine ohne Kreativität und Verstand, die ich damit beauftragt habe). Zweitens sind trotz aller Auswahl und vieler verworfener Versuche noch immer einige Inkonsistenzen zu entdecken. Einige davon habe ich schon für das obige Mockup mit der Bildbearbeitung meines Vertrauens zu eliminieren versucht, aber noch einmal -- ich bin kein Pixelartist.

Trotzdem bin ich mit dem Ergebnis recht zufrieden und werde die Bildchen in meinem geplanten Tuesday&nbsp;JS Test einsetzen. Denn erst in der Anwendung zeigt sich, ob das Erreichte wirklich etwas taugt. *Still digging!*

---

**Bild**: *[Mockup für eine Visual Novel](https://www.flickr.com/photos/schockwellenreiter/53518059577/)*, erstellt mit [Scenario](http://cognitiones.kantel-chaos-team.de/technikgeschichte/rechnerundnetze/scenario.html) und [DreamStudio](https://beta.dreamstudio.ai/generate).